{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Reachability and Latency Forecasting with RIPE Atlas\n",
    "This project is accesible at: https://github.com/rita-imdea/ripe-userguide\n",
    "\n",
    "## II) Retrieving data from RIPE Atlas\n",
    "\n",
    "In this notebook, we are going to see how to retrieve measurements fron RIPE Atlas and also how to parse measurements from JSON files (which have been pre-downloaded from RIPE Atlas). \n",
    "We recommend the reader to first take a look at the PDF document that contains the guide for the whole course. \n",
    "\n",
    "------------------------------\n",
    "To complete:\n",
    "!!!!!!!!!!!!!!!!\n",
    "This notebook is divided in XXX parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the Atlas api key an easy to remember variable name \n",
    "ATLAS_API_KEY = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # to create http requests from Python\n",
    "import json # Library to write and ready JSON files in PYthon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) ACCESSING PUBLICLY AVAILABLE MEASUREMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving data from the RIPE Atlas database in Python is very simple. \n",
    "One only needs to know the ID that indentifies the measurement. Then, it is enough to run the following code.\n",
    "The id provided is a ramdom id measurement that you can substitute with your measurement's ids if you create customized measurements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set the IDs of the measurements we want to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the measurement IDs you want to retrieve\n",
    "measurement_ids = [\"61142052\"] # example of measurement ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each measurement, we save the data in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through the measurement IDs and retrieve the JSON files\n",
    "for measurement_id in measurement_ids:\n",
    "        url = f\"https://atlas.ripe.net/api/v2/measurements/{measurement_id}/results/?format=json\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "                json_data = response.json()\n",
    "                \n",
    "                measurement_file = f\"RIPE-Atlas-measurement-{measurement_id}.json\" # Name of the JSON file where the data will be stored. \n",
    "                \n",
    "                # Write the JSON data to a file\n",
    "                with open(measurement_file, \"w\") as f:\n",
    "                        json.dump(json_data, f, indent=4)\n",
    "                        \n",
    "        else:\n",
    "                print(f\"Failed to retrieve measurement {measurement_id}. Error code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) PARSING YOUR MEASUREMENTS\n",
    "\n",
    "Next, we are going to get the data from the JSON files (which can be already present in the course directory or could be obtained with the above code). The next steps are:\n",
    "\n",
    "1. Initially, we parse the JSON files and store the data in a Python structure. \n",
    "2. We clean the data\n",
    "\n",
    "-----------------------------------------\n",
    "\n",
    "!!!!!!!!!!!!!!!! To complete\n",
    "\n",
    "3. Finally you can plot the probability distribution to see how the data is spread "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set the IDs of the measurements we are interested in. \n",
    "In this case, the IDs provided below refer to the measurements taken for this course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_ids = [\"48819905\", \"48819906\", \"48819907\", \"48819908\", \"48819909\", \"48819910\"] # example of measurement ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Reading JSON files in Python\n",
    "\n",
    "Next, we use the Python library \"json\", which allows us to ready and write JSON files with Python.\n",
    "Furthermore, we use two of the most used packages for data processing in PYthon: Pandas and Numpy. \n",
    "\n",
    "1. Pandas is a Python library that provides a data structure called a DataFrame (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html), which is a structure that facilitates data processing and manipulation. We shall use it to parse our data because it provides a number of useful functions for manipulation and visualization of data.\n",
    "\n",
    "2. Numpy is a Python library that facilitates mathematical operations, in particular for arrays and matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first import the necessary libraries \n",
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each one of the measurements, we read the JSON file and store it in a pandas DataFrame (df) structure.\n",
    "\n",
    "Then, we create a list of DataFrames (df) with all the measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the measurement IDs experiment files and create a DataFrame for each\n",
    "dfs = []\n",
    "for measurement_id in measurement_ids:\n",
    "    # Read the JSON data from the file\n",
    "    with open(f\"RIPE-Atlas-measurement-{measurement_id}.json\", \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    # Normalize the JSON data into a pandas DataFrame\n",
    "    df = pd.json_normalize(json_data)\n",
    "    \n",
    "    # Append the DataFrame to the list of DataFrames\n",
    "    dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to have all the DataFrames together to analyze all the measurements at the same time. Thus, we concatenate the list of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the DataFrames into a single one\n",
    "result_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the current data structure thanks to the pandas function \"head\", which prints the first 5 rows of the DataFrame with the value of all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fw</th>\n",
       "      <th>mver</th>\n",
       "      <th>lts</th>\n",
       "      <th>dst_name</th>\n",
       "      <th>af</th>\n",
       "      <th>dst_addr</th>\n",
       "      <th>src_addr</th>\n",
       "      <th>proto</th>\n",
       "      <th>ttl</th>\n",
       "      <th>size</th>\n",
       "      <th>...</th>\n",
       "      <th>prb_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>msm_name</th>\n",
       "      <th>from</th>\n",
       "      <th>type</th>\n",
       "      <th>group_id</th>\n",
       "      <th>step</th>\n",
       "      <th>stored_timestamp</th>\n",
       "      <th>endtime</th>\n",
       "      <th>paris_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5040</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>14</td>\n",
       "      <td>52.46.72.50</td>\n",
       "      <td>4</td>\n",
       "      <td>52.46.72.50</td>\n",
       "      <td>10.18.246.209</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>234.0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1003454</td>\n",
       "      <td>1673864005</td>\n",
       "      <td>Ping</td>\n",
       "      <td>51.15.99.8</td>\n",
       "      <td>ping</td>\n",
       "      <td>48819905</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1673864050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5040</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>20</td>\n",
       "      <td>52.46.72.50</td>\n",
       "      <td>4</td>\n",
       "      <td>52.46.72.50</td>\n",
       "      <td>10.109.0.30</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>233.0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1003747</td>\n",
       "      <td>1673864003</td>\n",
       "      <td>Ping</td>\n",
       "      <td>45.137.88.145</td>\n",
       "      <td>ping</td>\n",
       "      <td>48819905</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1673864114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5080</td>\n",
       "      <td>2.6.2</td>\n",
       "      <td>96</td>\n",
       "      <td>52.46.72.50</td>\n",
       "      <td>4</td>\n",
       "      <td>52.46.72.50</td>\n",
       "      <td>192.168.250.65</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>233.0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>20757</td>\n",
       "      <td>1673863991</td>\n",
       "      <td>Ping</td>\n",
       "      <td>82.116.160.225</td>\n",
       "      <td>ping</td>\n",
       "      <td>48819905</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1673864089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5080</td>\n",
       "      <td>2.6.2</td>\n",
       "      <td>12</td>\n",
       "      <td>52.46.72.50</td>\n",
       "      <td>4</td>\n",
       "      <td>52.46.72.50</td>\n",
       "      <td>192.168.1.38</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>234.0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>53229</td>\n",
       "      <td>1673864019</td>\n",
       "      <td>Ping</td>\n",
       "      <td>83.54.157.101</td>\n",
       "      <td>ping</td>\n",
       "      <td>48819905</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1673864090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5080</td>\n",
       "      <td>2.6.2</td>\n",
       "      <td>33</td>\n",
       "      <td>52.46.72.50</td>\n",
       "      <td>4</td>\n",
       "      <td>52.46.72.50</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>232.0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>51381</td>\n",
       "      <td>1673864074</td>\n",
       "      <td>Ping</td>\n",
       "      <td>102.34.0.4</td>\n",
       "      <td>ping</td>\n",
       "      <td>48819905</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1673864205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fw   mver  lts     dst_name  af     dst_addr        src_addr proto  \\\n",
       "0  5040  2.4.1   14  52.46.72.50   4  52.46.72.50   10.18.246.209  ICMP   \n",
       "1  5040  2.4.1   20  52.46.72.50   4  52.46.72.50     10.109.0.30  ICMP   \n",
       "2  5080  2.6.2   96  52.46.72.50   4  52.46.72.50  192.168.250.65  ICMP   \n",
       "3  5080  2.6.2   12  52.46.72.50   4  52.46.72.50    192.168.1.38  ICMP   \n",
       "4  5080  2.6.2   33  52.46.72.50   4  52.46.72.50   192.168.0.101  ICMP   \n",
       "\n",
       "     ttl  size  ...   prb_id   timestamp  msm_name            from  type  \\\n",
       "0  234.0    64  ...  1003454  1673864005      Ping      51.15.99.8  ping   \n",
       "1  233.0    64  ...  1003747  1673864003      Ping   45.137.88.145  ping   \n",
       "2  233.0    64  ...    20757  1673863991      Ping  82.116.160.225  ping   \n",
       "3  234.0    64  ...    53229  1673864019      Ping   83.54.157.101  ping   \n",
       "4  232.0    64  ...    51381  1673864074      Ping      102.34.0.4  ping   \n",
       "\n",
       "   group_id   step  stored_timestamp  endtime  paris_id  \n",
       "0  48819905  300.0        1673864050      NaN       NaN  \n",
       "1  48819905  300.0        1673864114      NaN       NaN  \n",
       "2  48819905  300.0        1673864089      NaN       NaN  \n",
       "3  48819905  300.0        1673864090      NaN       NaN  \n",
       "4  48819905  300.0        1673864205      NaN       NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the resulting DataFrame\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         14.612530\n",
       "1         24.125096\n",
       "2         22.542065\n",
       "3         26.183208\n",
       "4        171.458986\n",
       "            ...    \n",
       "17427           NaN\n",
       "17428           NaN\n",
       "17429           NaN\n",
       "17430           NaN\n",
       "17431           NaN\n",
       "Name: avg, Length: 17432, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Data cleaning and pre-processing\n",
    "\n",
    "The following step is to clean the data collection. \n",
    "\n",
    "For that, we should first know that the RIPE Atlas measurements may include negative values for latency (-1.0), which represent samples for which it was not possible to store the value (Due to, for example, timeouts in the netowrk protocols). \n",
    "\n",
    "To avoid that these values impact the later analysis, we remove those samples. We first transform the negative values into Not-a-Number values (NaN), and we make use of the function \"dropna\" from Pandas library to remove those samples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data \n",
    "\n",
    "# Change them to NaN\n",
    "result_df['avg'].replace(-1.0, np.nan, inplace=True)\n",
    "\n",
    "# Remove Null values \n",
    "result_df = result_df.dropna(how='any',axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further pre-process the data to facilitate the plotting, visualization and readability of the data.\n",
    "\n",
    "For that, we change the probe ID with an acronym that represents the country where the probe is located, plus an index in case there are several probes in the same country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fw</th>\n",
       "      <th>mver</th>\n",
       "      <th>lts</th>\n",
       "      <th>dst_name</th>\n",
       "      <th>af</th>\n",
       "      <th>dst_addr</th>\n",
       "      <th>src_addr</th>\n",
       "      <th>proto</th>\n",
       "      <th>ttl</th>\n",
       "      <th>size</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>msm_name</th>\n",
       "      <th>from</th>\n",
       "      <th>type</th>\n",
       "      <th>group_id</th>\n",
       "      <th>step</th>\n",
       "      <th>stored_timestamp</th>\n",
       "      <th>endtime</th>\n",
       "      <th>paris_id</th>\n",
       "      <th>nprb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fw mver  lts dst_name  af dst_addr src_addr proto  ttl  size  ...  \\\n",
       "0  NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "1  NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "2  NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "3  NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "4  NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "5  NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "6  NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "7  NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "8  NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "9  NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "10 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "11 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "12 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "13 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "14 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "15 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "16 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "17 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "18 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "19 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "20 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "21 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "22 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "23 NaN  NaN  NaN      NaN NaN      NaN      NaN   NaN  NaN   NaN  ...   \n",
       "\n",
       "   timestamp  msm_name  from  type  group_id  step  stored_timestamp  endtime  \\\n",
       "0        NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "1        NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "2        NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "3        NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "4        NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "5        NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "6        NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "7        NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "8        NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "9        NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "10       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "11       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "12       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "13       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "14       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "15       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "16       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "17       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "18       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "19       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "20       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "21       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "22       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "23       NaN       NaN   NaN   NaN       NaN   NaN               NaN      NaN   \n",
       "\n",
       "    paris_id  nprb_id  \n",
       "0        NaN      es1  \n",
       "1        NaN      es1  \n",
       "2        NaN      es1  \n",
       "3        NaN      es1  \n",
       "4        NaN      es1  \n",
       "5        NaN      es1  \n",
       "6        NaN      es1  \n",
       "7        NaN      es1  \n",
       "8        NaN      es1  \n",
       "9        NaN      es1  \n",
       "10       NaN      es1  \n",
       "11       NaN      es1  \n",
       "12       NaN      es1  \n",
       "13       NaN      es1  \n",
       "14       NaN      es1  \n",
       "15       NaN      es1  \n",
       "16       NaN      es1  \n",
       "17       NaN      es1  \n",
       "18       NaN      es1  \n",
       "19       NaN      es1  \n",
       "20       NaN      es1  \n",
       "21       NaN      es1  \n",
       "22       NaN      es1  \n",
       "23       NaN      es1  \n",
       "\n",
       "[24 rows x 29 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming the probe_id column for easy plotting \n",
    "nprb_id = []\n",
    "\n",
    "for value in df[\"prb_id\"]:\n",
    "    if value == 1004991:\n",
    "        nprb_id.append('es1')\n",
    "   \n",
    "        \n",
    "        \n",
    "result_df[\"nprb_id\"] = nprb_id\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the time column from epoch to date time format for time series processing \n",
    "new_timestamp = []\n",
    "\n",
    "for i in result_df['timestamp']:\n",
    "    my_datetime = datetime.fromtimestamp(i)\n",
    "    new_timestamp.append(my_datetime)\n",
    "\n",
    "df = result_df.copy()\n",
    "df['new_time'] = new_timestamp\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name = []\n",
    "\n",
    "for value in df[\"nprb_id\"]:\n",
    "    if (value == 'es1') or (value == 'es2') or(value == 'es3') or( value == 'es4'):\n",
    "        country_name.append('Spain')\n",
    "    if(value == 'nl1') or (value == 'nl2')or (value == 'nl3'):\n",
    "        country_name.append('Netherlands')\n",
    "    if(value == 'pt1') or (value == 'pt2'):\n",
    "        country_name.append('Portugal')\n",
    "    if(value == 'us1') or (value == 'us2'):\n",
    "        country_name.append('USA')\n",
    "    if(value == 'ug1'):\n",
    "        country_name.append('Uganda')\n",
    "        \n",
    "df['country_name'] = country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the probability distribution\n",
    "# checking cdf for each of the probes\n",
    "probes = ['es1','es2','es3','es4','nl1','nl3','pt2','ug1','us1','us2']\n",
    "\n",
    "for probe in probes:\n",
    "    df_cdf = df[(df['nprb_id'] == probe)]\n",
    "    axx = df_cdf['avg'].hist(cumulative=True, density=True, bins=100, alpha = 0.3)\n",
    "axx.legend(probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking pdf for each of the probes\n",
    "countries = df['country_name'].unique()\n",
    "\n",
    "for country in countries:\n",
    "    df_pdf = df[(df['country_name'] == country)]\n",
    "    axx = df_pdf['avg'].hist(density=True, bins=100, alpha = 0.3)\n",
    "\n",
    "axx.legend(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) ANALYZING YOUR MEASUREMENTS \n",
    "\n",
    "1. First you do some feature engineering ie add features that may be missing but could be important like distance and probe status \n",
    "2. Check how latency varies over time, how mean and standard deviation vary over distance or any other interesting scenarios you can come up with \n",
    "3. Finally you can do some predictions based using established mathematical models or machine learning models and see what gives you best results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "# Collect the source probe information \n",
    "\n",
    "from ripe.atlas.cousteau import Probe  \n",
    "\n",
    "probe_id_list = []\n",
    "\n",
    "#extract the probe cordinates from ripe atlas \n",
    "probe_coordinates = []\n",
    "probe_country = []\n",
    "\n",
    "for id_i in probe_id_list:\n",
    "    probe = Probe(id=id_i) # Obtains all metadata of probe id_i\n",
    "    print(probe.geometry) #probe.geometry is a GeoJSON https://en.wikipedia.org/wiki/GeoJSON\n",
    "    probe_coordinates.append(probe.geometry['coordinates']) # saving to the list\n",
    "    probe_country.append(probe.country_code)\n",
    "\n",
    "longitude = []\n",
    "latitude = []\n",
    "\n",
    "for i in probe_coordinates:\n",
    "    longitude.append(i[0])\n",
    "    latitude.append(i[1])\n",
    "\n",
    "# create a probe metadata dataframe\n",
    "srcprobes_df = pd.DataFrame({'prb_id': probe_id_list,'longitude': longitude, 'latitude': latitude,'probe_country': probe_country})\n",
    "srcprobes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the destination probe information \n",
    "\n",
    "probe_id_list = []\n",
    "\n",
    "#extract the probe cordinates from ripe atlas \n",
    "probe_coordinates = []\n",
    "probe_country = []\n",
    "\n",
    "for id_i in probe_id_list:\n",
    "    probe = Probe(id=id_i) \n",
    "    print(probe.geometry) \n",
    "    probe_coordinates.append(probe.geometry['coordinates']) # saving to the list\n",
    "    probe_country.append(probe.country_code)\n",
    "\n",
    "longitude = []\n",
    "latitude = []\n",
    "\n",
    "for i in probe_coordinates:\n",
    "    longitude.append(i[0])\n",
    "    latitude.append(i[1])\n",
    "\n",
    "# create a probe metadata dataframe\n",
    "dstprobes_df = pd.DataFrame({'prb_id': probe_id_list,'longitude': longitude, 'latitude': latitude,'probe_country': probe_country})\n",
    "dstprobes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the distances between all possible source probe and destination probe pairs \n",
    "from geopy.distance import distance\n",
    "from itertools import product\n",
    "\n",
    "# Create an empty list to store the distances\n",
    "data = []\n",
    "\n",
    "# Iterate over each combination of source and destination probes\n",
    "for source_row, dest_row in product(srcprobes_df.iterrows(), dstprobes_df.iterrows()):\n",
    "    source_row = source_row[1]  # Get the row data from the iterator\n",
    "    dest_row = dest_row[1]  # Get the row data from the iterator\n",
    "    \n",
    "    source_coordinates = (source_row['latitude'], source_row['longitude'])\n",
    "    dest_coordinates = (dest_row['latitude'], dest_row['longitude'])\n",
    "    \n",
    "    distance_km = distance(source_coordinates, dest_coordinates).km\n",
    "    # Append data to the list\n",
    "    data.append({\n",
    "        'source_prb_id': source_row['prb_id'],\n",
    "        'source_longitude': source_row['longitude'],\n",
    "        'source_latitude': source_row['latitude'],\n",
    "        'destination_prb_id': dest_row['prb_id'],\n",
    "        'destination_longitude': dest_row['longitude'],\n",
    "        'destination_latitude': dest_row['latitude'],\n",
    "        'distance': distance_km\n",
    "    })\n",
    "\n",
    "# Create a new dataframe from the data list\n",
    "distance_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the new dataframe\n",
    "distance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map from the distance dataframe and and use it to map distances to all probes and all destinations \n",
    "\n",
    "# Create a dictionary mapping (source_prb_id, destination_prb_id) to distance\n",
    "distance_map = {(int(row['source_prb_id']), int(row['destination_prb_id'])): row['distance'] for _, row in distance_df.iterrows()}\n",
    "\n",
    "\n",
    "# Map the distance values to the existing DataFrame based on (source_prb_id, destination_prb_id)\n",
    "df['distance'] = df.apply(lambda row: distance_map.get((int(row['prb_id']), int(row['dst_id']))), axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "distance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the probe status \n",
    "# you have to download the connection log json files manually \n",
    "\n",
    "probe_id_list = []\n",
    "\n",
    "# Dictionary to store combined json files with probe status \n",
    "combined_dict = []\n",
    "\n",
    "# Iterate over servers\n",
    "for server in probe_id_list:\n",
    "    server_name = str(server)\n",
    "    \n",
    "    # Read JSON log file\n",
    "    log_file = server_name + '.json'\n",
    "    \n",
    "    results = process_data(log_file, server)\n",
    "        \n",
    "    # Append to combined dictionary\n",
    "    combined_dict.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries into a more accessible format\n",
    "uptime_dict = {}\n",
    "for d in combined_dict:\n",
    "    for server_id, uptime_ranges in d.items():\n",
    "        uptime_dict[server_id] = uptime_ranges\n",
    "#uptime_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the timestamp is within the server's uptime ranges\n",
    "def is_probe_up(probe_id, timestamp):\n",
    "    if probe_id in uptime_dict:\n",
    "        for uptime_range in uptime_dict[probe_id]:\n",
    "            if uptime_range['to'] is None:\n",
    "                if uptime_range['from'] <= timestamp:\n",
    "                    return \"connected\"\n",
    "            else:\n",
    "                if uptime_range['from'] <= timestamp <= uptime_range['to']:\n",
    "                    return \"connected\"\n",
    "    return \"disconnected\"\n",
    "\n",
    "# Iterate through the DataFrame and check if the timestamp occurred during the server's uptime\n",
    "df['probe_status'] = df.apply(lambda row: is_probe_up(row['prb_id'], row['timestamp']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking how mean and standard deviation vary over time \n",
    "\n",
    "grouped_data = df.groupby(['prb_id', 'dst_id'])\n",
    "mean = grouped_data['avg_rtt'].mean()\n",
    "std = grouped_data['avg_rtt'].std()\n",
    "distance = grouped_data['distance'].unique()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(distance, mean, label='Mean',color=\"BLUE\")\n",
    "plt.ylabel('Mean')\n",
    "plt.legend()\n",
    "plt.title('Mean and Standard Deviation vs. Distance')\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "plt.errorbar(distance, mean, yerr=std, fmt='o',label='Standard Deviation',color=\"GREEN\")\n",
    "\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tick_params(axis='x', which='both', bottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying some simple forecasting methods\n",
    "\n",
    "# Using the naive forecast\n",
    "df = df.assign(naive=df['rtt'].shift(1))\n",
    "# Replace NaN at top of value column with 0\n",
    "df['naive'] = df['naive'].fillna(method='ffill').fillna(0)\n",
    "\n",
    "# Testing the prediction accuracy for naive forecast\n",
    "se = (df['rtt'] - df['naive']) ** 2\n",
    "9 mse_naive = se.mean()\n",
    "10 mse_naive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential smoothing method\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "fit1 = SimpleExpSmoothing(df_sktime['avg']).fit()\n",
    "df['Simple-smoothing'] = SimpleExpSmoothing(df['avg']).fit().fittedvalues\n",
    "df[['avg','Simple-smoothing']].plot(title='Exponential Smoothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the decision tree \n",
    "# randomising the test and train data \n",
    "import itertools\n",
    "import random\n",
    "\n",
    "test_indices = []\n",
    "train_indices = []\n",
    "        \n",
    "array1 = df2['nprb_id'].unique()\n",
    "array2 = df2['dst_addr'].unique()\n",
    "\n",
    "# Creating all possible pairs\n",
    "pairs = list(itertools.product(array1, array2))\n",
    "\n",
    "# Randomly selecting 10 pairs\n",
    "selected_pairs = random.sample(pairs, 10)\n",
    "\n",
    "# Removing selected pairs from the original list\n",
    "for pair in selected_pairs:\n",
    "    pairs.remove(pair)\n",
    "\n",
    "# Creating separate lists\n",
    "selected_list = selected_pairs\n",
    "remaining_list = pairs\n",
    "\n",
    "train_dfs = []\n",
    "for i,k in remaining_list:\n",
    "    temp_df = df2.loc[(df2['nprb_id'] == i) & (df2['dst_addr'] == k)]\n",
    "            \n",
    "    # Append the piece to the selected data\n",
    "    train_dfs.append(temp_df)\n",
    "\n",
    "train_df = pd.concat(train_dfs)\n",
    "        \n",
    "test_dfs = []\n",
    "for i,k in selected_list:\n",
    "    temp_df = df2.loc[(df2['nprb_id'] == i) & (df2['dst_addr'] == k)]\n",
    "            \n",
    "    # Append the piece to the selected data\n",
    "    test_dfs.append(temp_df)\n",
    "\n",
    "test_df = pd.concat(train_dfs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select your features and target\n",
    "X_train = train_df['normalizzed_distance'].values.reshape(-1,1)\n",
    "y_train = train_df['normalizzed_avg'].values\n",
    "\n",
    "X_test = test_df['normalizzed_distance'].values.reshape(-1,1)\n",
    "y_test = test_df['normalizzed_avg'].values\n",
    "\n",
    "# Import the Machine learning libraries\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create a Decision Tree Regressor\n",
    "model = DecisionTreeRegressor()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the Decision Tree\n",
    "from sklearn.tree import export_graphviz\n",
    "tree_dot = export_graphviz(reg_tree,feature_names =[\"distance\"],out_file=None,rounded=True, filled=True)\n",
    "\n",
    "# Visualize the tree using Graphviz\n",
    "graph = graphviz.Source(tree_dot)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Modelling \n",
    "import tensorflow as tf\n",
    "from tensorflow. keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(steps,features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(Xtrain, y_train, epochs=20, verbose=0)\n",
    "y_pred = model.predict(Xtest)\n",
    "\n",
    "mse = mean_squared_error(y_pred,y_test[0:len(y_pred)])\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D ) LATENCY Vs DISTANCE \n",
    "Sample code below helps us see how latency would change depending on the distance and when/if you added servers to deliver the customer services "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References \n",
    "\n",
    "# Install Jupyter-MATLAB\n",
    "# https://am111.readthedocs.io/en/latest/jmatlab_install.html\n",
    "# Calling user-defined MATLAB functions from Python\n",
    "# https://www.mathworks.com/help/matlab/matlab_external/call-user-script-and-function-from-python.html\n",
    "\n",
    "\n",
    "# Check if python version is 64bit or 32bit\n",
    "# Then download the corresponding MATLAB version \n",
    "# import sys\n",
    "# print(sys.maxsize > 2**32)\n",
    "\n",
    "# MATLAB-side configuration\n",
    "# First Install MATLAB from this website https://www.mathworks.com/\n",
    "# Get the matlab root directory by running <matlabroot> in the MATLAB command window\n",
    "# Add the matlabroot/bin to the system path\n",
    "# export PATH=\"/Applications/MATLAB_R2019b.app/bin:$PATH\"\n",
    "\n",
    "# SETUP MATLAB ENGINE API FOR PYTHON\n",
    "# cd /usr/local/MATLAB/R2018a/extern/engines/python -  change to your matlab version\n",
    "# python setup.py install // change setup tools if this fails pip install setuptools==58.2.0\n",
    "\n",
    "# JUPYTER SIDE CONFIGURATION \n",
    "# python -m matlab_kernel install --user //this adds matlab to the jupyter kernels list\n",
    "# jupyter kernelspec list //check if matlab is in the list\n",
    "# pip install matlab.engine\n",
    "\n",
    "import matlab.engine\n",
    "\n",
    "# Start a MATLAB session\n",
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oct2py import Oct2Py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Oct2PyError",
     "evalue": "octave not found, please see README",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\cloud\\lib\\site-packages\\oct2py\\core.py\u001b[0m in \u001b[0;36mrestart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOctaveEngine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstdin_handler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_stdin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cloud\\lib\\site-packages\\octave_kernel\\kernel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, error_handler, stream_handler, line_handler, stdin_handler, plot_settings, inline_toolkit, defer_startup, cli_options, logger)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_executable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcli_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcli_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cloud\\lib\\site-packages\\octave_kernel\\kernel.py\u001b[0m in \u001b[0;36m_get_executable\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    485\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexecutable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'octave not found, please see README'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mexecutable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: octave not found, please see README",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOct2PyError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_44040\\1126367128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOct2Py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\cloud\\lib\\site-packages\\oct2py\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logger, timeout, oned_as, temp_dir, convert_to_float, backend)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_user_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_ptrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cloud\\lib\\site-packages\\oct2py\\core.py\u001b[0m in \u001b[0;36mrestart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOctaveEngine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstdin_handler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_stdin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mOct2PyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;31m# Add local Octave scripts.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOct2PyError\u001b[0m: octave not found, please see README"
     ]
    }
   ],
   "source": [
    "oc = Oct2Py()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "script = \"function y = myScript(x)\\n\" \\\n",
    "         \"    y = x-5\" \\\n",
    "         \"end\"\n",
    "\n",
    "with open(\"myScript.m\",\"w+\") as f:\n",
    "    f.write(script)\n",
    "\n",
    "oc.PoA_student_workshop(nargout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the matlab simulation \n",
    "eng.PoA_student_workshop(nargout=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
